{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import SaveModelCallback\n",
    "import os\n",
    "#from sklearn.model_selection import KFold\n",
    "from radam import *\n",
    "from csvlogger import *\n",
    "from mish_activation import *\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score,confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "fastai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 128\n",
    "bs = 32\n",
    "nfolds = 4\n",
    "SEED = 2020\n",
    "N = 12 #number of tiles per image\n",
    "TRAIN = '../input/panda-16x128x128-tiles-data/train/'\n",
    "LABELS = '../input/prostate-cancer-grade-assessment/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(LABELS).set_index('image_id')\n",
    "files = sorted(set([p[:32] for p in os.listdir(TRAIN)]))\n",
    "df = df.loc[files]\n",
    "df = df.reset_index()\n",
    "splits = StratifiedKFold(n_splits=nfolds, random_state=SEED, shuffle=True)\n",
    "splits = list(splits.split(df,df.isup_grade))\n",
    "folds_splits = np.zeros(len(df)).astype(np.int)\n",
    "for i in range(nfolds): folds_splits[splits[i][1]] = i\n",
    "df['split'] = folds_splits\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.tensor([1.0-0.90949707, 1.0-0.8188697, 1.0-0.87795304])\n",
    "std = torch.tensor([0.36357649, 0.49984502, 0.40477625])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_image(fn:PathOrStr, div:bool=True, convert_mode:str='RGB', cls:type=Image,\n",
    "        after_open:Callable=None)->Image:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", UserWarning) # EXIF warning from TiffPlugin\n",
    "        x = PIL.Image.open(fn).convert(convert_mode)\n",
    "    if after_open: x = after_open(x)\n",
    "    x = pil2tensor(x,np.float32)\n",
    "    if div: x.div_(255)\n",
    "    return cls(1.0-x) #invert image for zero padding\n",
    "\n",
    "class MImage(ItemBase):\n",
    "    def __init__(self, imgs):\n",
    "        self.obj, self.data = \\\n",
    "          (imgs), [(imgs[i].data - mean[...,None,None])/std[...,None,None] for i in range(len(imgs))]\n",
    "    \n",
    "    def apply_tfms(self, tfms,*args, **kwargs):\n",
    "        for i in range(len(self.obj)):\n",
    "            self.obj[i] = self.obj[i].apply_tfms(tfms, *args, **kwargs)\n",
    "            self.data[i] = (self.obj[i].data - mean[...,None,None])/std[...,None,None]\n",
    "        return self\n",
    "    \n",
    "    def __repr__(self): return f'{self.__class__.__name__} {img.shape for img in self.obj}'\n",
    "    def to_one(self):\n",
    "        img = torch.stack(self.data,1)\n",
    "        img = img.view(3,-1,N,sz,sz).permute(0,1,3,2,4).contiguous().view(3,-1,sz*N)\n",
    "        return Image(1.0 - (mean[...,None,None]+img*std[...,None,None]))\n",
    "\n",
    "class MImageItemList(ImageList):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def __len__(self)->int: return len(self.items) or 1 \n",
    "    \n",
    "    def get(self, i):\n",
    "        fn = Path(self.items[i])\n",
    "        fnames = [Path(str(fn)+'_'+str(i)+'.png')for i in range(N)]\n",
    "        imgs = [open_image(fname, convert_mode=self.convert_mode, after_open=self.after_open)\n",
    "               for fname in fnames]\n",
    "        return MImage(imgs)\n",
    "\n",
    "    def reconstruct(self, t):\n",
    "        return MImage([mean[...,None,None]+_t*std[...,None,None] for _t in t])\n",
    "    \n",
    "    def show_xys(self, xs, ys, figsize:Tuple[int,int]=(300,50), **kwargs):\n",
    "        rows = min(len(xs),8)\n",
    "        fig, axs = plt.subplots(rows,1,figsize=figsize)\n",
    "        for i, ax in enumerate(axs.flatten() if rows > 1 else [axs]):\n",
    "            xs[i].to_one().show(ax=ax, y=ys[i], **kwargs)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "\n",
    "#collate function to combine multiple images into one tensor\n",
    "def MImage_collate(batch:ItemsList)->Tensor:\n",
    "    result = torch.utils.data.dataloader.default_collate(to_data(batch))\n",
    "    if isinstance(result[0],list):\n",
    "        result = [torch.stack(result[0],1),result[1]]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(fold=0):\n",
    "    return (MImageItemList.from_df(df, path='.', folder=TRAIN, cols='image_id')\n",
    "      .split_by_idx(df.index[df.split == fold].tolist())\n",
    "      .label_from_df(cols=['isup_grade'])\n",
    "      .transform(get_transforms(flip_vert=True,max_rotate=15),size=sz,padding_mode='zeros')\n",
    "      .databunch(bs=bs,num_workers=4))\n",
    "\n",
    "data = get_data(0)\n",
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, arch='resnext50_32x4d_ssl', n=6, pre=True):\n",
    "        super().__init__()\n",
    "        m = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', arch)\n",
    "        self.enc = nn.Sequential(*list(m.children())[:-2])       \n",
    "        nc = list(m.children())[-1].in_features\n",
    "        self.head = nn.Sequential(AdaptiveConcatPool2d(),Flatten(),nn.Linear(2*nc,512),\n",
    "                            Mish(),nn.BatchNorm1d(512), nn.Dropout(0.5),nn.Linear(512,n))\n",
    "        \n",
    "    def forward(self, *x):\n",
    "        shape = x[0].shape\n",
    "        n = len(x)\n",
    "        x = torch.stack(x,1).view(-1,shape[1],shape[2],shape[3])\n",
    "        #x: bs*N x 3 x 128 x 128\n",
    "        x = self.enc(x)\n",
    "        #x: bs*N x C x 4 x 4\n",
    "        shape = x.shape\n",
    "        #concatenate the output for tiles into a single map\n",
    "        x = x.view(-1,n,shape[1],shape[2],shape[3]).permute(0,2,1,3,4).contiguous()\\\n",
    "          .view(-1,shape[1],shape[2]*n,shape[3])\n",
    "        #x: bs x C x N*4 x 4\n",
    "        x = self.head(x)\n",
    "        #x: bs x n\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'RNXT50'\n",
    "pred,target = [],[]\n",
    "for fold in range(nfolds):\n",
    "    data = get_data(fold)\n",
    "    model = Model()\n",
    "    learn = Learner(data, model, loss_func=nn.CrossEntropyLoss(), opt_func=Over9000, \n",
    "                metrics=[KappaScore(weights='quadratic')]).to_fp16()\n",
    "    logger = CSVLogger(learn, f'log_{fname}_{fold}')\n",
    "    learn.clip_grad = 1.0\n",
    "    learn.split([model.head])\n",
    "    learn.unfreeze()\n",
    "\n",
    "    learn.fit_one_cycle(16, max_lr=1e-3, div_factor=100, pct_start=0.0, \n",
    "      callbacks = [SaveModelCallback(learn,name=f'model',monitor='kappa_score')])\n",
    "    torch.save(learn.model.state_dict(), f'{fname}_{fold}.pth')\n",
    "    \n",
    "    learn.model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, (x, y) in progress_bar(enumerate(data.dl(DatasetType.Valid)),\n",
    "                                     total=len(data.dl(DatasetType.Valid))):\n",
    "            p = learn.model(*x)\n",
    "            pred.append(p.float().cpu())\n",
    "            target.append(y.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
